{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Image Dataset into Hdf5 Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = 'C://caltech101//101_ObjectCategories'  # dataset path\n",
    "\n",
    "save_path = './/tesp.hdf5'  # path to save the hdf5 file\n",
    "\n",
    "hf = h5py.File(save_path, 'a')  # open the file in append mode\n",
    "for i in os.listdir(base_path):\n",
    "    if i== \"BACKGROUND_Google\": # Removeing the BACKGROUND_Google\n",
    "        continue\n",
    "    # read all as' inside A\n",
    "    vid_name = os.path.join(base_path, i)\n",
    "    grp = hf.create_group(i)  # create a subgroup for the above created group. each small\n",
    "                                      # a is one subgroup\n",
    "\n",
    "    for k in os.listdir(vid_name):   # find all images inside a.\n",
    "        img_path = os.path.join(vid_name, k)\n",
    "\n",
    "        with open(img_path, 'rb') as img_f:  # open images as python binary\n",
    "            binary_data = img_f.read()\n",
    "\n",
    "        binary_data_np = np.asarray(binary_data)\n",
    "\n",
    "        dset = grp.create_dataset(k, data=binary_data_np) # save it in the subgroup. each a-subgroup contains all the images.\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning the Image from Hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "\n",
    "\n",
    "save_path = './/Caltech_101.hdf5'  # path to save the hdf5 file\n",
    "data = []  # list all images files full path 'group/subgroup/b.png' for e.g. ./A/a/b.png. These are basically keys to access our image data.\n",
    "\n",
    "group= [] # list all groups and subgroups in hdf5 file\n",
    "\n",
    "def func(name, obj):     # function to recursively store all the keys\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        data.append(name)\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        group.append(name)\n",
    "\n",
    "hf = h5py.File(save_path, 'r')\n",
    "hf.visititems(func)  # this is the operation we are talking about.\n",
    "print(\"No. of total images : \", len(data))\n",
    "print(\"No. of Groups : \", len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from scipy.fftpack import dct, idct\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "# implement 2D DCT\n",
    "def dct2(a):\n",
    "    return dct(dct(a.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "# implement 2D IDCT\n",
    "def idct2(a):\n",
    "    return idct(idct(a.T, norm='ortho').T, norm='ortho') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "features=[]\n",
    "\n",
    "\n",
    "for j in data:\n",
    "    kk = np.array(hf[j])\n",
    "    img = Image.open(io.BytesIO(kk))# our image file\n",
    "    gray_image = ImageOps.grayscale(img)\n",
    "    img=gray_image.resize((128,64))\n",
    "    img1=np.asarray(gray_image)\n",
    "    imF = dct2(img1)\n",
    "    im1 = idct2(imF)\n",
    "    LL, (LH, HL, HH) = pywt.dwt2(im1, 'db2')\n",
    "    fdA, hog_image = hog(im, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "    features.append(list(fdA)\n",
    "    t=j.find('/')\n",
    "    labels.append(group.index(j[:t]))\n",
    "feature1=np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split data 15%-85% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature1, labels, test_size=0.15, random_state=0,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature1.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(random_state=42) # instantiate\n",
    "model=model.fit(X_train, y_train) # train the classifier\n",
    "prediction = model.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1 = RandomForestClassifier(random_state=1000)\n",
    "model1=model1.fit(X_train, y_train) # train the classifier\n",
    "prediction1 = model1.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, prediction1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Set regularization rate\n",
    "reg = 1\n",
    "# train a logistic regression model on the training set\n",
    "model3 = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "prediction3 = model3.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, prediction3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model5 = DecisionTreeClassifier(random_state=1000)\n",
    "model5=model5.fit(X_train, y_train)\n",
    "prediction5 = model5.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, prediction5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('SGD_101.sav', 'wb'))\n",
    "pickle.dump(model, open('RandomFores_101.sav', 'wb'))\n",
    "pickle.dump(model, open('LogisticRegression_101.sav', 'wb'))\n",
    "pickle.dump(model, open('DecisionTree_101.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
