{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pywt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# implement 2D DCT\n",
    "def dct2(a):\n",
    "    return dct(dct(a.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "# implement 2D IDCT\n",
    "def idct2(a):\n",
    "    return idct(idct(a.T, norm='ortho').T, norm='ortho')   \n",
    "data_path=\"D:\\\\Project ICOD\\\\101_ObjectCategories\"\n",
    "files = os.listdir(data_path)\n",
    "cat=[]\n",
    "for name in files:\n",
    "    cat+=[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accordion\n",
      "airplanes\n",
      "anchor\n",
      "ant\n",
      "BACKGROUND_Google\n",
      "barrel\n",
      "bass\n",
      "beaver\n",
      "binocular\n",
      "bonsai\n",
      "brain\n",
      "brontosaurus\n",
      "buddha\n",
      "butterfly\n",
      "camera\n",
      "cannon\n",
      "car_side\n",
      "ceiling_fan\n",
      "cellphone\n",
      "chair\n",
      "chandelier\n",
      "cougar_body\n",
      "cougar_face\n",
      "crab\n",
      "crayfish\n",
      "crocodile\n",
      "crocodile_head\n",
      "cup\n",
      "dalmatian\n",
      "dollar_bill\n",
      "dolphin\n",
      "dragonfly\n",
      "electric_guitar\n",
      "elephant\n",
      "emu\n",
      "euphonium\n",
      "ewer\n",
      "Faces\n",
      "Faces_easy\n",
      "ferry\n",
      "flamingo\n",
      "flamingo_head\n",
      "garfield\n",
      "gerenuk\n",
      "gramophone\n",
      "grand_piano\n",
      "hawksbill\n",
      "headphone\n",
      "hedgehog\n",
      "helicopter\n",
      "ibis\n",
      "inline_skate\n",
      "joshua_tree\n",
      "kangaroo\n",
      "ketch\n",
      "lamp\n",
      "laptop\n",
      "Leopards\n",
      "llama\n",
      "lobster\n",
      "lotus\n",
      "mandolin\n",
      "mayfly\n",
      "menorah\n",
      "metronome\n",
      "minaret\n",
      "Motorbikes\n",
      "nautilus\n",
      "octopus\n",
      "okapi\n",
      "pagoda\n",
      "panda\n",
      "pigeon\n",
      "pizza\n",
      "platypus\n",
      "pyramid\n",
      "revolver\n",
      "rhino\n",
      "rooster\n",
      "saxophone\n",
      "schooner\n",
      "scissors\n",
      "scorpion\n",
      "sea_horse\n",
      "snoopy\n",
      "soccer_ball\n",
      "stapler\n",
      "starfish\n",
      "stegosaurus\n",
      "stop_sign\n",
      "strawberry\n",
      "sunflower\n",
      "tick\n",
      "trilobite\n",
      "umbrella\n",
      "watch\n",
      "water_lilly\n",
      "wheelchair\n",
      "wild_cat\n",
      "windsor_chair\n",
      "wrench\n",
      "yin_yang\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "fd_trainA=[]\n",
    "\n",
    "for i in cat:\n",
    "    path=os.path.join(data_path,i)\n",
    "    print(i)\n",
    "    for img in os.listdir(path):\n",
    "        image=os.path.join(path,img)\n",
    "         \n",
    "        train_data=cv2.imread(image)\n",
    "    \n",
    "        \n",
    "        img=cv2.cvtColor(train_data,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #DCT -Discrete Cosine Transform\n",
    "        imF = dct2(img)\n",
    "        im1 = idct2(imF)\n",
    "        \n",
    "        # Resize image to 128x64 (for Hog - 8x8)\n",
    "        im_resize = resize(im1, (128, 64))\n",
    "        \n",
    "        #Daubechies Wavelet\n",
    "        coeffs2 = pywt.dwt2(im_resize, 'db2')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "        \n",
    "        # Approximation Detail - (Apply hog 8x8 -orientations=9 -)\n",
    "        fdA, hog_image = hog(LL, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "        fd_trainA +=[ np.append(fdA,cat.index(i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('HOG_DCT_dbWaveletA_101_30_70.csv',fd_trainA, delimiter=',',fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "      <th>751</th>\n",
       "      <th>752</th>\n",
       "      <th>753</th>\n",
       "      <th>754</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221305</td>\n",
       "      <td>0.315734</td>\n",
       "      <td>0.230509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.021161</td>\n",
       "      <td>0.315734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238805</td>\n",
       "      <td>0.354308</td>\n",
       "      <td>0.354308</td>\n",
       "      <td>0.185510</td>\n",
       "      <td>0.078410</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107656</td>\n",
       "      <td>0.390136</td>\n",
       "      <td>0.189516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.279087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060661</td>\n",
       "      <td>0.182709</td>\n",
       "      <td>0.233924</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111178</td>\n",
       "      <td>0.098157</td>\n",
       "      <td>0.120019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.374433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363467</td>\n",
       "      <td>0.366459</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.434419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227003</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058371</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>0.097919</td>\n",
       "      <td>0.125679</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.041398</td>\n",
       "      <td>0.147289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081366</td>\n",
       "      <td>0.175020</td>\n",
       "      <td>0.049481</td>\n",
       "      <td>0.192140</td>\n",
       "      <td>0.073160</td>\n",
       "      <td>0.107323</td>\n",
       "      <td>0.033401</td>\n",
       "      <td>0.050496</td>\n",
       "      <td>0.167434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067238</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.081870</td>\n",
       "      <td>0.025659</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.019021</td>\n",
       "      <td>0.057332</td>\n",
       "      <td>0.017538</td>\n",
       "      <td>0.054336</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>0.120821</td>\n",
       "      <td>0.406491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127852</td>\n",
       "      <td>0.170565</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.020516</td>\n",
       "      <td>0.079393</td>\n",
       "      <td>0.065246</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.271783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110084</td>\n",
       "      <td>0.263747</td>\n",
       "      <td>0.158077</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.057359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9144 rows × 757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.221305  0.315734  0.230509  0.000000  0.004723  0.000000  0.000000   \n",
       "1     0.107656  0.390136  0.189516  0.000000  0.017928  0.000008  0.005986   \n",
       "2     0.111178  0.098157  0.120019  0.000000  0.000000  0.000000  0.007003   \n",
       "3     0.000086  0.000119  0.000000  0.000000  0.000310  0.000000  0.000002   \n",
       "4     0.058371  0.173620  0.027868  0.097919  0.125679  0.050882  0.021739   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9139  0.001315  0.000044  0.000000  0.000000  0.000003  0.000000  0.000039   \n",
       "9140  0.000017  0.000000  0.000000  0.000001  0.000000  0.000000  0.000000   \n",
       "9141  0.091421  0.041435  0.034306  0.019021  0.057332  0.017538  0.054336   \n",
       "9142  0.000057  0.000819  0.000067  0.000000  0.000005  0.000000  0.000000   \n",
       "9143  0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000005   \n",
       "\n",
       "           7         8         9    ...       747       748       749  \\\n",
       "0     0.008694  0.021161  0.315734  ...  0.238805  0.354308  0.354308   \n",
       "1     0.003991  0.012217  0.279087  ...  0.060661  0.182709  0.233924   \n",
       "2     0.009380  0.000276  0.374433  ...  0.363467  0.366459  0.028356   \n",
       "3     0.000000  0.000123  0.434419  ...  0.227003  0.000647  0.000531   \n",
       "4     0.000238  0.041398  0.147289  ...  0.081366  0.175020  0.049481   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9139  0.004027  0.000656  0.129573  ...  0.067238  0.154667  0.062450   \n",
       "9140  0.000000  0.000001  0.000513  ...  0.000000  0.000000  0.000000   \n",
       "9141  0.064161  0.120821  0.406491  ...  0.127852  0.170565  0.022911   \n",
       "9142  0.000000  0.000462  0.271783  ...  0.110084  0.263747  0.158077   \n",
       "9143  0.000000  0.000000  0.105031  ...  0.000482  0.009186  0.011531   \n",
       "\n",
       "           750       751       752       753       754       755    756  \n",
       "0     0.185510  0.078410  0.009937  0.000000  0.000000  0.031050    0.0  \n",
       "1     0.019270  0.013222  0.000000  0.008695  0.004020  0.011712    0.0  \n",
       "2     0.000000  0.000000  0.016154  0.016995  0.000000  0.000000    0.0  \n",
       "3     0.000052  0.000234  0.000000  0.000000  0.000000  0.000247    0.0  \n",
       "4     0.192140  0.073160  0.107323  0.033401  0.050496  0.167434    0.0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "9139  0.001274  0.081870  0.025659  0.000357  0.000000  0.003757  101.0  \n",
       "9140  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  101.0  \n",
       "9141  0.005766  0.007276  0.010091  0.020516  0.079393  0.065246  101.0  \n",
       "9142  0.204869  0.057359  0.000000  0.041231  0.000000  0.000022  101.0  \n",
       "9143  0.000719  0.000003  0.000000  0.000000  0.000010  0.000034  101.0  \n",
       "\n",
       "[9144 rows x 757 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# load the training dataset\n",
    "#images = pd.read_csv('array1.csv',header=None)\n",
    "images = pd.read_csv('HOG_DCT_dbWaveletA_101_30_70.csv',header=None)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.21305e-01, 3.15734e-01, 2.30509e-01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 3.10500e-02],\n",
       "       [1.07656e-01, 3.90136e-01, 1.89516e-01, ..., 8.69500e-03,\n",
       "        4.02000e-03, 1.17120e-02],\n",
       "       [1.11178e-01, 9.81570e-02, 1.20019e-01, ..., 1.69950e-02,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [9.14210e-02, 4.14350e-02, 3.43060e-02, ..., 2.05160e-02,\n",
       "        7.93930e-02, 6.52460e-02],\n",
       "       [5.70000e-05, 8.19000e-04, 6.70000e-05, ..., 4.12310e-02,\n",
       "        0.00000e+00, 2.20000e-05],\n",
       "       [1.00000e-06, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e-05, 3.40000e-05]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=images[range(756)].values,images[756].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split data 15%-85% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9144, 756)\n",
      "(2743, 756)\n",
      "(6401, 756)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 1\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [38. 12. 10. ... 66. 12. 20.]\n",
      "Actual labels:     [38. 47. 10. ... 66. 80. 20.]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5308545539759413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.63      0.70        41\n",
      "         1.0       0.80      0.96      0.88       560\n",
      "         2.0       1.00      0.06      0.11        34\n",
      "         3.0       0.17      0.03      0.05        31\n",
      "         4.0       0.21      0.49      0.29       333\n",
      "         5.0       0.50      0.03      0.06        34\n",
      "         6.0       0.00      0.00      0.00        44\n",
      "         7.0       0.00      0.00      0.00        34\n",
      "         8.0       1.00      0.07      0.14        27\n",
      "         9.0       0.32      0.59      0.41        81\n",
      "        10.0       0.37      0.59      0.45        63\n",
      "        11.0       0.75      0.09      0.17        32\n",
      "        12.0       0.45      0.55      0.49        55\n",
      "        13.0       0.29      0.31      0.30        64\n",
      "        14.0       0.46      0.15      0.23        39\n",
      "        15.0       0.20      0.03      0.06        29\n",
      "        16.0       0.67      0.93      0.78        85\n",
      "        17.0       0.08      0.03      0.05        31\n",
      "        18.0       0.66      0.75      0.70        36\n",
      "        19.0       0.60      0.43      0.50        42\n",
      "        20.0       0.38      0.43      0.40        75\n",
      "        21.0       0.22      0.06      0.09        36\n",
      "        22.0       0.45      0.39      0.42        51\n",
      "        23.0       0.13      0.12      0.12        49\n",
      "        24.0       0.33      0.07      0.12        55\n",
      "        25.0       0.00      0.00      0.00        35\n",
      "        26.0       0.00      0.00      0.00        39\n",
      "        27.0       0.56      0.12      0.20        40\n",
      "        28.0       0.14      0.09      0.11        44\n",
      "        29.0       0.88      0.54      0.67        41\n",
      "        30.0       0.11      0.04      0.06        47\n",
      "        31.0       0.81      0.48      0.60        52\n",
      "        32.0       0.45      0.50      0.47        44\n",
      "        33.0       0.32      0.24      0.28        45\n",
      "        34.0       0.20      0.05      0.08        38\n",
      "        35.0       0.63      0.45      0.53        42\n",
      "        36.0       0.53      0.45      0.49        60\n",
      "        37.0       0.64      0.97      0.77       305\n",
      "        38.0       0.80      0.98      0.88       302\n",
      "        39.0       0.47      0.30      0.37        46\n",
      "        40.0       0.36      0.08      0.13        50\n",
      "        41.0       0.30      0.11      0.16        27\n",
      "        42.0       1.00      0.20      0.33        25\n",
      "        43.0       0.00      0.00      0.00        26\n",
      "        44.0       0.86      0.32      0.46        38\n",
      "        45.0       0.85      0.77      0.81        71\n",
      "        46.0       0.19      0.40      0.26        68\n",
      "        47.0       0.50      0.23      0.32        30\n",
      "        48.0       0.20      0.02      0.04        43\n",
      "        49.0       0.44      0.32      0.37        63\n",
      "        50.0       0.21      0.53      0.31        49\n",
      "        51.0       1.00      0.29      0.45        24\n",
      "        52.0       0.28      0.38      0.32        40\n",
      "        53.0       0.20      0.44      0.28        57\n",
      "        54.0       0.52      0.59      0.55        83\n",
      "        55.0       0.50      0.24      0.33        45\n",
      "        56.0       0.76      0.56      0.65        57\n",
      "        57.0       0.42      0.85      0.56       144\n",
      "        58.0       0.26      0.14      0.18        59\n",
      "        59.0       0.08      0.03      0.05        29\n",
      "        60.0       0.08      0.02      0.03        47\n",
      "        61.0       0.57      0.26      0.36        31\n",
      "        62.0       0.25      0.04      0.06        28\n",
      "        63.0       0.78      0.67      0.72        64\n",
      "        64.0       0.93      0.74      0.82        19\n",
      "        65.0       0.98      0.87      0.92        46\n",
      "        66.0       0.85      0.96      0.90       562\n",
      "        67.0       0.25      0.14      0.18        37\n",
      "        68.0       0.00      0.00      0.00        26\n",
      "        69.0       0.11      0.04      0.06        26\n",
      "        70.0       0.75      0.80      0.77        30\n",
      "        71.0       0.25      0.04      0.06        27\n",
      "        72.0       0.67      0.20      0.31        30\n",
      "        73.0       0.25      0.08      0.12        38\n",
      "        74.0       0.36      0.19      0.25        21\n",
      "        75.0       0.62      0.20      0.30        40\n",
      "        76.0       0.88      0.75      0.81        57\n",
      "        77.0       0.28      0.20      0.23        40\n",
      "        78.0       0.76      0.59      0.67        32\n",
      "        79.0       1.00      0.09      0.17        32\n",
      "        80.0       0.50      0.08      0.14        49\n",
      "        81.0       0.56      0.43      0.49        23\n",
      "        82.0       0.22      0.17      0.19        58\n",
      "        83.0       0.12      0.02      0.04        42\n",
      "        84.0       0.80      0.17      0.28        24\n",
      "        85.0       0.46      0.24      0.32        45\n",
      "        86.0       0.50      0.31      0.38        26\n",
      "        87.0       0.13      0.24      0.17        54\n",
      "        88.0       0.64      0.34      0.44        41\n",
      "        89.0       0.82      0.34      0.48        41\n",
      "        90.0       1.00      0.04      0.08        23\n",
      "        91.0       0.14      0.39      0.21        51\n",
      "        92.0       0.67      0.17      0.27        36\n",
      "        93.0       0.73      0.76      0.75        68\n",
      "        94.0       0.56      0.33      0.41        46\n",
      "        95.0       0.57      0.75      0.65       177\n",
      "        96.0       0.00      0.00      0.00        27\n",
      "        97.0       0.43      0.15      0.22        41\n",
      "        98.0       0.14      0.05      0.07        20\n",
      "        99.0       0.95      0.49      0.64        39\n",
      "       100.0       0.73      0.32      0.44        25\n",
      "       101.0       0.94      0.77      0.85        43\n",
      "\n",
      "    accuracy                           0.53      6401\n",
      "   macro avg       0.48      0.32      0.34      6401\n",
      "weighted avg       0.54      0.53      0.50      6401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,   0,   0, ...,   0,   0,   0],\n",
       "       [  0, 538,   0, ...,   0,   0,   0],\n",
       "       [  1,   1,   2, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   4,   0, ...,  19,   0,   0],\n",
       "       [  0,   3,   0, ...,   0,   8,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,  33]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
