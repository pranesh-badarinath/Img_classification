{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pywt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "data_path=\"E:\\\\Panduranga\\\\Downloads\\\\caltech101\\\\101_ObjectCategories\"\n",
    "files = os.listdir(data_path)\n",
    "cat=[]\n",
    "for name in files:\n",
    "    cat+=[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accordion\n",
      "airplanes\n",
      "anchor\n",
      "ant\n",
      "BACKGROUND_Google\n",
      "barrel\n",
      "bass\n",
      "beaver\n",
      "binocular\n",
      "bonsai\n",
      "brain\n",
      "brontosaurus\n",
      "buddha\n",
      "butterfly\n",
      "camera\n",
      "cannon\n",
      "car_side\n",
      "ceiling_fan\n",
      "cellphone\n",
      "chair\n",
      "chandelier\n",
      "cougar_body\n",
      "cougar_face\n",
      "crab\n",
      "crayfish\n",
      "crocodile\n",
      "crocodile_head\n",
      "cup\n",
      "dalmatian\n",
      "dollar_bill\n",
      "dolphin\n",
      "dragonfly\n",
      "electric_guitar\n",
      "elephant\n",
      "emu\n",
      "euphonium\n",
      "ewer\n",
      "Faces\n",
      "Faces_easy\n",
      "ferry\n",
      "flamingo\n",
      "flamingo_head\n",
      "garfield\n",
      "gerenuk\n",
      "gramophone\n",
      "grand_piano\n",
      "hawksbill\n",
      "headphone\n",
      "hedgehog\n",
      "helicopter\n",
      "ibis\n",
      "inline_skate\n",
      "joshua_tree\n",
      "kangaroo\n",
      "ketch\n",
      "lamp\n",
      "laptop\n",
      "Leopards\n",
      "llama\n",
      "lobster\n",
      "lotus\n",
      "mandolin\n",
      "mayfly\n",
      "menorah\n",
      "metronome\n",
      "minaret\n",
      "Motorbikes\n",
      "nautilus\n",
      "octopus\n",
      "okapi\n",
      "pagoda\n",
      "panda\n",
      "pigeon\n",
      "pizza\n",
      "platypus\n",
      "pyramid\n",
      "revolver\n",
      "rhino\n",
      "rooster\n",
      "saxophone\n",
      "schooner\n",
      "scissors\n",
      "scorpion\n",
      "sea_horse\n",
      "snoopy\n",
      "soccer_ball\n",
      "stapler\n",
      "starfish\n",
      "stegosaurus\n",
      "stop_sign\n",
      "strawberry\n",
      "sunflower\n",
      "tick\n",
      "trilobite\n",
      "umbrella\n",
      "watch\n",
      "water_lilly\n",
      "wheelchair\n",
      "wild_cat\n",
      "windsor_chair\n",
      "wrench\n",
      "yin_yang\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "fd_trainH=[]\n",
    "fd_trainV=[]\n",
    "fd_trainD=[]\n",
    "fd_trainA=[]\n",
    "\n",
    "for i in cat:\n",
    "    path=os.path.join(data_path,i)\n",
    "    print(i)\n",
    "    for img in os.listdir(path):\n",
    "        image=os.path.join(path,img)\n",
    "         \n",
    "        train_data=cv2.imread(image)\n",
    "        \n",
    "        #Principal component analysis\n",
    "        blue,green,red = cv2.split(train_data)\n",
    "        #it will split the original image into Blue, Green and Red arrays.\n",
    "        #initialize PCA with first 50 principal components\n",
    "        pca = PCA(50)\n",
    "\n",
    "        #Applying to red channel and then applying inverse transform to transformed array.\n",
    "        red_transformed = pca.fit_transform(red)\n",
    "        red_inverted = pca.inverse_transform(red_transformed)\n",
    "\n",
    "        #Applying to Green channel and then applying inverse transform to transformed array.\n",
    "        green_transformed = pca.fit_transform(green)\n",
    "        green_inverted = pca.inverse_transform(green_transformed)\n",
    "\n",
    "        #Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "        blue_transformed = pca.fit_transform(blue)\n",
    "        blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "\n",
    "        img_compressed = (np.dstack((red_inverted, green_inverted, blue_inverted))).astype(np.uint8)\n",
    "        img=cv2.cvtColor(img_compressed,cv2.COLOR_BGR2GRAY)\n",
    "        img = resize(img, (128, 64))\n",
    "        \n",
    "        #Daubechies Wavelet\n",
    "        coeffs2 = pywt.dwt2(img, 'db2')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "        \n",
    "        # Approximation\n",
    "        fdA, hog_image = hog(LL, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "        fd_trainA +=[ np.append(fdA,cat.index(i))]\n",
    "        \n",
    "        # Horizontal\n",
    "        fdH, hog_image = hog(LH, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "        fd_trainH +=[ np.append(fdH,cat.index(i))]\n",
    "        \n",
    "        #Vertical\n",
    "        fdV, hog_image = hog(HL, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "        fd_trainV +=[ np.append(fdV,cat.index(i))]\n",
    "        \n",
    "        #diagonal\n",
    "        fdD, hog_image = hog(HH, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "        fd_trainD +=[ np.append(fdD,cat.index(i))]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('HOG_PCS50_dbWaveletA.csv',fd_trainA, delimiter=',',fmt='%f')\n",
    "np.savetxt('HOG_PCS50_dbWaveletH.csv',fd_trainH, delimiter=',',fmt='%f')\n",
    "np.savetxt('HOG_PCS50_dbWaveletV.csv',fd_trainV, delimiter=',',fmt='%f')\n",
    "np.savetxt('HOG_PCS50_dbWaveletD.csv',fd_trainD, delimiter=',',fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "      <th>751</th>\n",
       "      <th>752</th>\n",
       "      <th>753</th>\n",
       "      <th>754</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234803</td>\n",
       "      <td>0.248588</td>\n",
       "      <td>0.136302</td>\n",
       "      <td>0.121093</td>\n",
       "      <td>0.210252</td>\n",
       "      <td>0.123376</td>\n",
       "      <td>0.097966</td>\n",
       "      <td>0.107737</td>\n",
       "      <td>0.111874</td>\n",
       "      <td>0.248588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230711</td>\n",
       "      <td>0.275870</td>\n",
       "      <td>0.280130</td>\n",
       "      <td>0.254020</td>\n",
       "      <td>0.222008</td>\n",
       "      <td>0.143890</td>\n",
       "      <td>0.040110</td>\n",
       "      <td>0.090846</td>\n",
       "      <td>0.141809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388997</td>\n",
       "      <td>0.388997</td>\n",
       "      <td>0.202880</td>\n",
       "      <td>0.037811</td>\n",
       "      <td>0.366877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062623</td>\n",
       "      <td>0.119384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168830</td>\n",
       "      <td>0.254303</td>\n",
       "      <td>0.254303</td>\n",
       "      <td>0.120459</td>\n",
       "      <td>0.139923</td>\n",
       "      <td>0.072708</td>\n",
       "      <td>0.254303</td>\n",
       "      <td>0.097498</td>\n",
       "      <td>0.207117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139069</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.131507</td>\n",
       "      <td>0.092885</td>\n",
       "      <td>0.207594</td>\n",
       "      <td>0.148463</td>\n",
       "      <td>0.086753</td>\n",
       "      <td>0.151354</td>\n",
       "      <td>0.160979</td>\n",
       "      <td>0.263512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164253</td>\n",
       "      <td>0.202408</td>\n",
       "      <td>0.167975</td>\n",
       "      <td>0.137825</td>\n",
       "      <td>0.113543</td>\n",
       "      <td>0.167231</td>\n",
       "      <td>0.093886</td>\n",
       "      <td>0.125813</td>\n",
       "      <td>0.195165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188939</td>\n",
       "      <td>0.249757</td>\n",
       "      <td>0.105425</td>\n",
       "      <td>0.154262</td>\n",
       "      <td>0.251360</td>\n",
       "      <td>0.068356</td>\n",
       "      <td>0.084283</td>\n",
       "      <td>0.078215</td>\n",
       "      <td>0.029758</td>\n",
       "      <td>0.323802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255274</td>\n",
       "      <td>0.220984</td>\n",
       "      <td>0.255274</td>\n",
       "      <td>0.088429</td>\n",
       "      <td>0.244567</td>\n",
       "      <td>0.124272</td>\n",
       "      <td>0.092321</td>\n",
       "      <td>0.085413</td>\n",
       "      <td>0.165380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231749</td>\n",
       "      <td>0.172544</td>\n",
       "      <td>0.126384</td>\n",
       "      <td>0.234780</td>\n",
       "      <td>0.299435</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.073975</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.299435</td>\n",
       "      <td>0.299435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>0.101984</td>\n",
       "      <td>0.121253</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>0.199468</td>\n",
       "      <td>0.136590</td>\n",
       "      <td>0.042501</td>\n",
       "      <td>0.068924</td>\n",
       "      <td>0.107564</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125875</td>\n",
       "      <td>0.244789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>0.221858</td>\n",
       "      <td>0.102411</td>\n",
       "      <td>0.102681</td>\n",
       "      <td>0.103094</td>\n",
       "      <td>0.143182</td>\n",
       "      <td>0.074362</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.146195</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>0.233853</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.083962</td>\n",
       "      <td>0.084290</td>\n",
       "      <td>0.195049</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.146469</td>\n",
       "      <td>0.064501</td>\n",
       "      <td>0.255388</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>0.161382</td>\n",
       "      <td>0.027037</td>\n",
       "      <td>0.044851</td>\n",
       "      <td>0.021378</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.094981</td>\n",
       "      <td>0.105885</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.084969</td>\n",
       "      <td>0.397459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109284</td>\n",
       "      <td>0.148033</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.045229</td>\n",
       "      <td>0.052213</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.027642</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.283542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159314</td>\n",
       "      <td>0.308855</td>\n",
       "      <td>0.115818</td>\n",
       "      <td>0.215310</td>\n",
       "      <td>0.039685</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.039069</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>0.243880</td>\n",
       "      <td>0.063607</td>\n",
       "      <td>0.028833</td>\n",
       "      <td>0.092769</td>\n",
       "      <td>0.124824</td>\n",
       "      <td>0.114988</td>\n",
       "      <td>0.048647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106212</td>\n",
       "      <td>0.062344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114591</td>\n",
       "      <td>0.033619</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.045943</td>\n",
       "      <td>0.028185</td>\n",
       "      <td>0.020622</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>0.084413</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9145 rows Ã— 757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.234803  0.248588  0.136302  0.121093  0.210252  0.123376  0.097966   \n",
       "1     0.388997  0.388997  0.202880  0.037811  0.366877  0.000000  0.000000   \n",
       "2     0.139069  0.075187  0.131507  0.092885  0.207594  0.148463  0.086753   \n",
       "3     0.188939  0.249757  0.105425  0.154262  0.251360  0.068356  0.084283   \n",
       "4     0.231749  0.172544  0.126384  0.234780  0.299435  0.004545  0.073975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9140  0.199468  0.136590  0.042501  0.068924  0.107564  0.021488  0.069620   \n",
       "9141  0.233853  0.054863  0.083962  0.084290  0.195049  0.091566  0.146469   \n",
       "9142  0.161382  0.027037  0.044851  0.021378  0.078243  0.094981  0.105885   \n",
       "9143  0.026826  0.025372  0.027642  0.002002  0.011808  0.006158  0.005703   \n",
       "9144  0.243880  0.063607  0.028833  0.092769  0.124824  0.114988  0.048647   \n",
       "\n",
       "           7         8         9    ...       747       748       749  \\\n",
       "0     0.107737  0.111874  0.248588  ...  0.230711  0.275870  0.280130   \n",
       "1     0.000000  0.062623  0.119384  ...  0.168830  0.254303  0.254303   \n",
       "2     0.151354  0.160979  0.263512  ...  0.164253  0.202408  0.167975   \n",
       "3     0.078215  0.029758  0.323802  ...  0.255274  0.220984  0.255274   \n",
       "4     0.002901  0.299435  0.299435  ...  0.158923  0.236805  0.236805   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9140  0.000000  0.125875  0.244789  ...  0.244888  0.221858  0.102411   \n",
       "9141  0.064501  0.255388  0.008955  ...  0.144639  0.000000  0.000000   \n",
       "9142  0.022119  0.084969  0.397459  ...  0.109284  0.148033  0.031822   \n",
       "9143  0.004250  0.006807  0.283542  ...  0.159314  0.308855  0.115818   \n",
       "9144  0.000000  0.106212  0.062344  ...  0.114591  0.033619  0.035524   \n",
       "\n",
       "           750       751       752       753       754       755    756  \n",
       "0     0.254020  0.222008  0.143890  0.040110  0.090846  0.141809    0.0  \n",
       "1     0.120459  0.139923  0.072708  0.254303  0.097498  0.207117    0.0  \n",
       "2     0.137825  0.113543  0.167231  0.093886  0.125813  0.195165    0.0  \n",
       "3     0.088429  0.244567  0.124272  0.092321  0.085413  0.165380    0.0  \n",
       "4     0.236805  0.073111  0.236805  0.101984  0.121253  0.236805    0.0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "9140  0.102681  0.103094  0.143182  0.074362  0.024354  0.146195  101.0  \n",
       "9141  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  101.0  \n",
       "9142  0.008892  0.020480  0.002799  0.045229  0.052213  0.083616  101.0  \n",
       "9143  0.215310  0.039685  0.009087  0.004203  0.039069  0.014981  101.0  \n",
       "9144  0.007579  0.045943  0.028185  0.020622  0.011056  0.084413  101.0  \n",
       "\n",
       "[9145 rows x 757 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# load the training dataset\n",
    "#images = pd.read_csv('array1.csv',header=None)\n",
    "images = pd.read_csv('HOG_PCS50_dbWaveletA.csv',header=None)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=images[range(756)].values,images[756].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.234803, 0.248588, 0.136302, ..., 0.04011 , 0.090846, 0.141809],\n",
       "       [0.388997, 0.388997, 0.20288 , ..., 0.254303, 0.097498, 0.207117],\n",
       "       [0.139069, 0.075187, 0.131507, ..., 0.093886, 0.125813, 0.195165],\n",
       "       ...,\n",
       "       [0.161382, 0.027037, 0.044851, ..., 0.045229, 0.052213, 0.083616],\n",
       "       [0.026826, 0.025372, 0.027642, ..., 0.004203, 0.039069, 0.014981],\n",
       "       [0.24388 , 0.063607, 0.028833, ..., 0.020622, 0.011056, 0.084413]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split data 15%-85% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.85, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9145, 756)\n",
      "(1371, 756)\n",
      "(7774, 756)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 1\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [30. 27. 35. ... 89. 35. 76.]\n",
      "Actual labels:     [30. 27. 35. ... 89. 23. 76.]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4406997684589658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44        49\n",
      "         1.0       0.81      0.94      0.87       686\n",
      "         2.0       0.00      0.00      0.00        39\n",
      "         3.0       0.00      0.00      0.00        39\n",
      "         4.0       0.15      0.51      0.23       410\n",
      "         5.0       0.38      0.22      0.28        36\n",
      "         6.0       0.00      0.00      0.00        48\n",
      "         7.0       0.00      0.00      0.00        43\n",
      "         8.0       0.00      0.00      0.00        29\n",
      "         9.0       0.15      0.39      0.21       104\n",
      "        10.0       0.25      0.24      0.24        83\n",
      "        11.0       0.00      0.00      0.00        38\n",
      "        12.0       0.45      0.24      0.31        72\n",
      "        13.0       0.18      0.17      0.17        78\n",
      "        14.0       0.60      0.07      0.12        44\n",
      "        15.0       0.20      0.06      0.10        32\n",
      "        16.0       0.78      0.80      0.79       107\n",
      "        17.0       0.22      0.05      0.09        38\n",
      "        18.0       0.73      0.45      0.56        49\n",
      "        19.0       0.35      0.12      0.17        52\n",
      "        20.0       0.26      0.34      0.29        88\n",
      "        21.0       0.14      0.03      0.04        39\n",
      "        22.0       0.54      0.22      0.32        58\n",
      "        23.0       0.11      0.05      0.07        61\n",
      "        24.0       0.38      0.05      0.09        61\n",
      "        25.0       0.00      0.00      0.00        42\n",
      "        26.0       0.00      0.00      0.00        46\n",
      "        27.0       0.54      0.14      0.23        49\n",
      "        28.0       0.18      0.07      0.10        55\n",
      "        29.0       0.89      0.17      0.28        48\n",
      "        30.0       0.25      0.08      0.12        53\n",
      "        31.0       0.54      0.24      0.33        58\n",
      "        32.0       0.41      0.17      0.24        64\n",
      "        33.0       0.19      0.07      0.11        54\n",
      "        34.0       0.00      0.00      0.00        46\n",
      "        35.0       0.34      0.45      0.39        49\n",
      "        36.0       0.43      0.32      0.37        71\n",
      "        37.0       0.66      0.96      0.78       372\n",
      "        38.0       0.75      0.98      0.85       368\n",
      "        39.0       0.24      0.21      0.22        53\n",
      "        40.0       0.25      0.04      0.06        57\n",
      "        41.0       0.30      0.08      0.12        38\n",
      "        42.0       1.00      0.07      0.13        29\n",
      "        43.0       0.00      0.00      0.00        31\n",
      "        44.0       1.00      0.07      0.12        45\n",
      "        45.0       0.58      0.52      0.55        84\n",
      "        46.0       0.30      0.31      0.30        85\n",
      "        47.0       0.00      0.00      0.00        36\n",
      "        48.0       0.00      0.00      0.00        47\n",
      "        49.0       0.37      0.22      0.28        76\n",
      "        50.0       0.23      0.27      0.25        67\n",
      "        51.0       0.00      0.00      0.00        30\n",
      "        52.0       0.18      0.24      0.20        51\n",
      "        53.0       0.25      0.30      0.27        71\n",
      "        54.0       0.39      0.51      0.44        96\n",
      "        55.0       0.22      0.08      0.12        49\n",
      "        56.0       0.91      0.41      0.57        70\n",
      "        57.0       0.25      0.75      0.37       161\n",
      "        58.0       0.08      0.01      0.02        69\n",
      "        59.0       0.00      0.00      0.00        36\n",
      "        60.0       1.00      0.02      0.03        59\n",
      "        61.0       0.31      0.15      0.20        34\n",
      "        62.0       0.33      0.03      0.06        32\n",
      "        63.0       0.44      0.18      0.25        78\n",
      "        64.0       0.59      0.43      0.50        23\n",
      "        65.0       0.73      0.62      0.67        61\n",
      "        66.0       0.69      0.98      0.81       678\n",
      "        67.0       0.19      0.11      0.14        44\n",
      "        68.0       0.00      0.00      0.00        31\n",
      "        69.0       0.00      0.00      0.00        35\n",
      "        70.0       0.54      0.58      0.56        38\n",
      "        71.0       0.00      0.00      0.00        33\n",
      "        72.0       0.38      0.26      0.31        35\n",
      "        73.0       0.14      0.07      0.09        43\n",
      "        74.0       0.25      0.04      0.06        27\n",
      "        75.0       0.47      0.17      0.25        46\n",
      "        76.0       0.76      0.30      0.43        73\n",
      "        77.0       0.20      0.02      0.04        52\n",
      "        78.0       0.75      0.14      0.24        43\n",
      "        79.0       0.00      0.00      0.00        37\n",
      "        80.0       0.80      0.07      0.13        55\n",
      "        81.0       0.25      0.17      0.20        29\n",
      "        82.0       0.11      0.07      0.09        70\n",
      "        83.0       0.00      0.00      0.00        50\n",
      "        84.0       0.00      0.00      0.00        30\n",
      "        85.0       0.00      0.00      0.00        56\n",
      "        86.0       0.17      0.03      0.05        37\n",
      "        87.0       0.28      0.11      0.15        75\n",
      "        88.0       0.36      0.08      0.13        52\n",
      "        89.0       0.86      0.21      0.34        56\n",
      "        90.0       1.00      0.03      0.06        30\n",
      "        91.0       0.10      0.48      0.17        65\n",
      "        92.0       0.22      0.10      0.14        41\n",
      "        93.0       0.54      0.72      0.61        74\n",
      "        94.0       0.29      0.18      0.22        62\n",
      "        95.0       0.41      0.70      0.52       203\n",
      "        96.0       0.00      0.00      0.00        31\n",
      "        97.0       0.08      0.02      0.03        49\n",
      "        98.0       0.00      0.00      0.00        29\n",
      "        99.0       0.67      0.08      0.14        50\n",
      "       100.0       0.00      0.00      0.00        34\n",
      "       101.0       0.90      0.16      0.28        55\n",
      "\n",
      "    accuracy                           0.44      7774\n",
      "   macro avg       0.33      0.20      0.21      7774\n",
      "weighted avg       0.44      0.44      0.39      7774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16   0   0 ...   0   0   0]\n",
      " [  0 645   0 ...   0   0   0]\n",
      " [  0   3   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   2   0 ...   4   0   0]\n",
      " [  0  10   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print (cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
