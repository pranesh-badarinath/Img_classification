{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pywt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# implement 2D DCT\n",
    "def dct2(a):\n",
    "    return dct(dct(a.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "# implement 2D IDCT\n",
    "def idct2(a):\n",
    "    return idct(idct(a.T, norm='ortho').T, norm='ortho')   \n",
    "data_path=\"E:\\\\Panduranga\\\\Downloads\\\\caltech101\\\\101_ObjectCategories\"\n",
    "files = os.listdir(data_path)\n",
    "cat=[]\n",
    "for name in files:\n",
    "    cat+=[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accordion\n",
      "airplanes\n",
      "anchor\n",
      "ant\n",
      "BACKGROUND_Google\n",
      "barrel\n",
      "bass\n",
      "beaver\n",
      "binocular\n",
      "bonsai\n",
      "brain\n",
      "brontosaurus\n",
      "buddha\n",
      "butterfly\n",
      "camera\n",
      "cannon\n",
      "car_side\n",
      "ceiling_fan\n",
      "cellphone\n",
      "chair\n",
      "chandelier\n",
      "cougar_body\n",
      "cougar_face\n",
      "crab\n",
      "crayfish\n",
      "crocodile\n",
      "crocodile_head\n",
      "cup\n",
      "dalmatian\n",
      "dollar_bill\n",
      "dolphin\n",
      "dragonfly\n",
      "electric_guitar\n",
      "elephant\n",
      "emu\n",
      "euphonium\n",
      "ewer\n",
      "Faces\n",
      "Faces_easy\n",
      "ferry\n",
      "flamingo\n",
      "flamingo_head\n",
      "garfield\n",
      "gerenuk\n",
      "gramophone\n",
      "grand_piano\n",
      "hawksbill\n",
      "headphone\n",
      "hedgehog\n",
      "helicopter\n",
      "ibis\n",
      "inline_skate\n",
      "joshua_tree\n",
      "kangaroo\n",
      "ketch\n",
      "lamp\n",
      "laptop\n",
      "Leopards\n",
      "llama\n",
      "lobster\n",
      "lotus\n",
      "mandolin\n",
      "mayfly\n",
      "menorah\n",
      "metronome\n",
      "minaret\n",
      "Motorbikes\n",
      "nautilus\n",
      "octopus\n",
      "okapi\n",
      "pagoda\n",
      "panda\n",
      "pigeon\n",
      "pizza\n",
      "platypus\n",
      "pyramid\n",
      "revolver\n",
      "rhino\n",
      "rooster\n",
      "saxophone\n",
      "schooner\n",
      "scissors\n",
      "scorpion\n",
      "sea_horse\n",
      "snoopy\n",
      "soccer_ball\n",
      "stapler\n",
      "starfish\n",
      "stegosaurus\n",
      "stop_sign\n",
      "strawberry\n",
      "sunflower\n",
      "tick\n",
      "trilobite\n",
      "umbrella\n",
      "watch\n",
      "water_lilly\n",
      "wheelchair\n",
      "wild_cat\n",
      "windsor_chair\n",
      "wrench\n",
      "yin_yang\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "fd_trainA=[]\n",
    "\n",
    "for i in cat:\n",
    "    path=os.path.join(data_path,i)\n",
    "    print(i)\n",
    "    for img in os.listdir(path):\n",
    "        image=os.path.join(path,img)\n",
    "         \n",
    "        train_data=cv2.imread(image)\n",
    "    \n",
    "        \n",
    "        img=cv2.cvtColor(train_data,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #DCT -Discrete Cosine Transform\n",
    "        imF = dct2(img)\n",
    "        im1 = idct2(imF)\n",
    "        \n",
    "        # Resize image to 128x64 (for Hog - 8x8)\n",
    "        im_resize = resize(im1, (128, 64))\n",
    "        \n",
    "        #Daubechies Wavelet\n",
    "        coeffs2 = pywt.dwt2(im_resize, 'db2')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "        \n",
    "        # Approximation Detail - (Apply hog 8x8 -orientations=9 -)\n",
    "        fdA, hog_image = hog(LL, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True)\n",
    "        fd_trainA +=[ np.append(fdA,cat.index(i))]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('HOG_DCT_dbWaveletA.csv',fd_trainA, delimiter=',',fmt='%f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "      <th>751</th>\n",
       "      <th>752</th>\n",
       "      <th>753</th>\n",
       "      <th>754</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221305</td>\n",
       "      <td>0.315734</td>\n",
       "      <td>0.230509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.021161</td>\n",
       "      <td>0.315734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238805</td>\n",
       "      <td>0.354308</td>\n",
       "      <td>0.354308</td>\n",
       "      <td>0.185510</td>\n",
       "      <td>0.078410</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107656</td>\n",
       "      <td>0.390136</td>\n",
       "      <td>0.189516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.279087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060661</td>\n",
       "      <td>0.182709</td>\n",
       "      <td>0.233924</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111178</td>\n",
       "      <td>0.098157</td>\n",
       "      <td>0.120019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.374433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363467</td>\n",
       "      <td>0.366459</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.434419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227003</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058371</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>0.097919</td>\n",
       "      <td>0.125679</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.041398</td>\n",
       "      <td>0.147289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081366</td>\n",
       "      <td>0.175020</td>\n",
       "      <td>0.049481</td>\n",
       "      <td>0.192140</td>\n",
       "      <td>0.073160</td>\n",
       "      <td>0.107323</td>\n",
       "      <td>0.033401</td>\n",
       "      <td>0.050496</td>\n",
       "      <td>0.167434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067238</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.081870</td>\n",
       "      <td>0.025659</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.019021</td>\n",
       "      <td>0.057332</td>\n",
       "      <td>0.017538</td>\n",
       "      <td>0.054336</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>0.120821</td>\n",
       "      <td>0.406491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127852</td>\n",
       "      <td>0.170565</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.020516</td>\n",
       "      <td>0.079393</td>\n",
       "      <td>0.065246</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.271783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.259968</td>\n",
       "      <td>0.155812</td>\n",
       "      <td>0.201934</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9145 rows × 757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.221305  0.315734  0.230509  0.000000  0.004723  0.000000  0.000000   \n",
       "1     0.107656  0.390136  0.189516  0.000000  0.017928  0.000008  0.005986   \n",
       "2     0.111178  0.098157  0.120019  0.000000  0.000000  0.000000  0.007003   \n",
       "3     0.000086  0.000119  0.000000  0.000000  0.000310  0.000000  0.000002   \n",
       "4     0.058371  0.173620  0.027868  0.097919  0.125679  0.050882  0.021739   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9140  0.001315  0.000044  0.000000  0.000000  0.000003  0.000000  0.000039   \n",
       "9141  0.000017  0.000000  0.000000  0.000001  0.000000  0.000000  0.000000   \n",
       "9142  0.091421  0.041435  0.034306  0.019021  0.057332  0.017538  0.054336   \n",
       "9143  0.000057  0.000819  0.000067  0.000000  0.000005  0.000000  0.000000   \n",
       "9144  0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000005   \n",
       "\n",
       "           7         8         9    ...       747       748       749  \\\n",
       "0     0.008694  0.021161  0.315734  ...  0.238805  0.354308  0.354308   \n",
       "1     0.003991  0.012217  0.279087  ...  0.060661  0.182709  0.233924   \n",
       "2     0.009380  0.000276  0.374433  ...  0.363467  0.366459  0.028356   \n",
       "3     0.000000  0.000123  0.434419  ...  0.227003  0.000647  0.000531   \n",
       "4     0.000238  0.041398  0.147289  ...  0.081366  0.175020  0.049481   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9140  0.004027  0.000656  0.129573  ...  0.067238  0.154667  0.062450   \n",
       "9141  0.000000  0.000001  0.000513  ...  0.000000  0.000000  0.000000   \n",
       "9142  0.064161  0.120821  0.406491  ...  0.127852  0.170565  0.022911   \n",
       "9143  0.000000  0.000462  0.271783  ...  0.108507  0.259968  0.155812   \n",
       "9144  0.000000  0.000000  0.105031  ...  0.000482  0.009186  0.011531   \n",
       "\n",
       "           750       751       752       753       754       755    756  \n",
       "0     0.185510  0.078410  0.009937  0.000000  0.000000  0.031050    0.0  \n",
       "1     0.019270  0.013222  0.000000  0.008695  0.004020  0.011712    0.0  \n",
       "2     0.000000  0.000000  0.016154  0.016995  0.000000  0.000000    0.0  \n",
       "3     0.000052  0.000234  0.000000  0.000000  0.000000  0.000247    0.0  \n",
       "4     0.192140  0.073160  0.107323  0.033401  0.050496  0.167434    0.0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "9140  0.001274  0.081870  0.025659  0.000357  0.000000  0.003757  101.0  \n",
       "9141  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  101.0  \n",
       "9142  0.005766  0.007276  0.010091  0.020516  0.079393  0.065246  101.0  \n",
       "9143  0.201934  0.056537  0.000000  0.040641  0.000000  0.000022  101.0  \n",
       "9144  0.000719  0.000003  0.000000  0.000000  0.000010  0.000034  101.0  \n",
       "\n",
       "[9145 rows x 757 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# load the training dataset\n",
    "#images = pd.read_csv('array1.csv',header=None)\n",
    "images = pd.read_csv('HOG_DCT_dbWaveletA.csv',header=None)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=images[range(756)].values,images[756].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.21305e-01, 3.15734e-01, 2.30509e-01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 3.10500e-02],\n",
       "       [1.07656e-01, 3.90136e-01, 1.89516e-01, ..., 8.69500e-03,\n",
       "        4.02000e-03, 1.17120e-02],\n",
       "       [1.11178e-01, 9.81570e-02, 1.20019e-01, ..., 1.69950e-02,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [9.14210e-02, 4.14350e-02, 3.43060e-02, ..., 2.05160e-02,\n",
       "        7.93930e-02, 6.52460e-02],\n",
       "       [5.70000e-05, 8.19000e-04, 6.70000e-05, ..., 4.06410e-02,\n",
       "        0.00000e+00, 2.20000e-05],\n",
       "       [1.00000e-06, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e-05, 3.40000e-05]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split data 15%-85% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.85, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9145, 756)\n",
      "(1371, 756)\n",
      "(7774, 756)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 1\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [30. 27. 35. ... 89. 23. 76.]\n",
      "Actual labels:     [30. 27. 35. ... 89. 23. 76.]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4839207615127348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.57      0.70        49\n",
      "         1.0       0.76      0.94      0.84       686\n",
      "         2.0       0.00      0.00      0.00        39\n",
      "         3.0       0.00      0.00      0.00        39\n",
      "         4.0       0.18      0.42      0.25       410\n",
      "         5.0       0.35      0.22      0.27        36\n",
      "         6.0       0.00      0.00      0.00        48\n",
      "         7.0       0.00      0.00      0.00        43\n",
      "         8.0       0.00      0.00      0.00        29\n",
      "         9.0       0.16      0.39      0.23       104\n",
      "        10.0       0.40      0.59      0.48        83\n",
      "        11.0       0.80      0.11      0.19        38\n",
      "        12.0       0.48      0.42      0.44        72\n",
      "        13.0       0.33      0.32      0.33        78\n",
      "        14.0       0.27      0.07      0.11        44\n",
      "        15.0       0.19      0.16      0.17        32\n",
      "        16.0       0.71      0.77      0.74       107\n",
      "        17.0       0.12      0.03      0.04        38\n",
      "        18.0       0.77      0.73      0.75        49\n",
      "        19.0       0.60      0.23      0.33        52\n",
      "        20.0       0.28      0.42      0.34        88\n",
      "        21.0       0.14      0.03      0.04        39\n",
      "        22.0       0.44      0.31      0.36        58\n",
      "        23.0       0.10      0.08      0.09        61\n",
      "        24.0       0.33      0.05      0.09        61\n",
      "        25.0       0.17      0.02      0.04        42\n",
      "        26.0       0.00      0.00      0.00        46\n",
      "        27.0       0.64      0.14      0.23        49\n",
      "        28.0       0.14      0.07      0.10        55\n",
      "        29.0       1.00      0.15      0.25        48\n",
      "        30.0       0.22      0.08      0.11        53\n",
      "        31.0       0.77      0.40      0.52        58\n",
      "        32.0       0.54      0.22      0.31        64\n",
      "        33.0       0.23      0.15      0.18        54\n",
      "        34.0       0.12      0.02      0.04        46\n",
      "        35.0       0.51      0.55      0.53        49\n",
      "        36.0       0.44      0.48      0.46        71\n",
      "        37.0       0.60      0.94      0.74       372\n",
      "        38.0       0.72      0.98      0.83       368\n",
      "        39.0       0.30      0.28      0.29        53\n",
      "        40.0       0.47      0.12      0.19        57\n",
      "        41.0       0.00      0.00      0.00        38\n",
      "        42.0       1.00      0.24      0.39        29\n",
      "        43.0       0.00      0.00      0.00        31\n",
      "        44.0       0.86      0.13      0.23        45\n",
      "        45.0       0.80      0.63      0.71        84\n",
      "        46.0       0.34      0.28      0.31        85\n",
      "        47.0       0.25      0.06      0.09        36\n",
      "        48.0       0.12      0.02      0.04        47\n",
      "        49.0       0.43      0.28      0.34        76\n",
      "        50.0       0.27      0.39      0.32        67\n",
      "        51.0       0.00      0.00      0.00        30\n",
      "        52.0       0.20      0.33      0.25        51\n",
      "        53.0       0.26      0.37      0.30        71\n",
      "        54.0       0.44      0.59      0.50        96\n",
      "        55.0       0.38      0.20      0.27        49\n",
      "        56.0       0.84      0.51      0.64        70\n",
      "        57.0       0.33      0.88      0.48       161\n",
      "        58.0       0.15      0.03      0.05        69\n",
      "        59.0       0.00      0.00      0.00        36\n",
      "        60.0       0.00      0.00      0.00        59\n",
      "        61.0       0.43      0.35      0.39        34\n",
      "        62.0       0.67      0.06      0.11        32\n",
      "        63.0       0.66      0.40      0.50        78\n",
      "        64.0       1.00      0.70      0.82        23\n",
      "        65.0       0.89      0.79      0.83        61\n",
      "        66.0       0.70      0.98      0.82       678\n",
      "        67.0       0.16      0.11      0.13        44\n",
      "        68.0       0.00      0.00      0.00        31\n",
      "        69.0       1.00      0.09      0.16        35\n",
      "        70.0       0.84      0.68      0.75        38\n",
      "        71.0       0.00      0.00      0.00        33\n",
      "        72.0       0.62      0.29      0.39        35\n",
      "        73.0       0.22      0.16      0.19        43\n",
      "        74.0       0.21      0.11      0.15        27\n",
      "        75.0       0.44      0.15      0.23        46\n",
      "        76.0       0.88      0.52      0.66        73\n",
      "        77.0       0.20      0.02      0.04        52\n",
      "        78.0       0.90      0.21      0.34        43\n",
      "        79.0       0.00      0.00      0.00        37\n",
      "        80.0       0.36      0.07      0.12        55\n",
      "        81.0       0.63      0.41      0.50        29\n",
      "        82.0       0.18      0.17      0.17        70\n",
      "        83.0       0.00      0.00      0.00        50\n",
      "        84.0       1.00      0.10      0.18        30\n",
      "        85.0       0.80      0.07      0.13        56\n",
      "        86.0       0.71      0.14      0.23        37\n",
      "        87.0       0.15      0.13      0.14        75\n",
      "        88.0       0.53      0.15      0.24        52\n",
      "        89.0       0.92      0.21      0.35        56\n",
      "        90.0       1.00      0.03      0.06        30\n",
      "        91.0       0.12      0.52      0.20        65\n",
      "        92.0       0.25      0.12      0.16        41\n",
      "        93.0       0.64      0.89      0.75        74\n",
      "        94.0       0.68      0.31      0.42        62\n",
      "        95.0       0.47      0.74      0.58       203\n",
      "        96.0       0.00      0.00      0.00        31\n",
      "        97.0       0.12      0.04      0.06        49\n",
      "        98.0       0.00      0.00      0.00        29\n",
      "        99.0       1.00      0.14      0.25        50\n",
      "       100.0       0.00      0.00      0.00        34\n",
      "       101.0       1.00      0.44      0.61        55\n",
      "\n",
      "    accuracy                           0.48      7774\n",
      "   macro avg       0.41      0.26      0.28      7774\n",
      "weighted avg       0.48      0.48      0.44      7774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28,   0,   0, ...,   0,   0,   0],\n",
       "       [  0, 646,   0, ...,   0,   0,   0],\n",
       "       [  0,   6,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   4,   0, ...,   7,   0,   0],\n",
       "       [  0,   4,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,  24]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
